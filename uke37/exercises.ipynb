{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e39cd7c",
   "metadata": {},
   "source": [
    "# Exercises week 37\n",
    "**Implementing gradient descent for Ridge and ordinary Least Squares Regression**\n",
    "\n",
    "Date: **September 8-12, 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4d1cc",
   "metadata": {},
   "source": [
    "## Simple one-dimensional second-order polynomial\n",
    "\n",
    "We start with a very simple function\n",
    "defined for $x\\in [-2,2]$. You can add noise if you wish. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81d7c6",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)= 2-x+5x^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6569500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_from_function(n=100, noise_level=0.1):\n",
    "    noise = np.random.normal(0, noise_level, n)\n",
    "    x = np.linspace(-2, 2, n)\n",
    "    y = 2 - x + 5 * x**2 + noise\n",
    "    return x, y\n",
    "\n",
    "x, y = sample_from_function(n=100, noise_level=0.1)\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63555e12",
   "metadata": {},
   "source": [
    "### 1a)\n",
    "\n",
    "We first need to create the feature matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b317066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(x, p):\n",
    "    n = len(x)\n",
    "    X = np.zeros((n, p+1))\n",
    "    for j in range(p+1):\n",
    "        X[:, j] = x**j\n",
    "    return X\n",
    "\n",
    "X = polynomial_features(x, 2)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf97351",
   "metadata": {},
   "source": [
    "Compute the mean and standard deviation of each column (feature) in your design/feature matrix $\\boldsymbol{X}$.\n",
    "Subtract the mean and divide by the standard deviation for each feature.\n",
    "\n",
    "We will also center the target $\\boldsymbol{y}$ to mean $0$. Centering $\\boldsymbol{y}$\n",
    "(and each feature) means the model does not require a separate intercept\n",
    "term, the data is shifted such that the intercept is effectively 0\n",
    ". (In practice, one could include an intercept in the model and not\n",
    "penalize it, but here we simplify by centering.)\n",
    "Choose $n=100$ data points and set up $\\boldsymbol{x}$, $\\boldsymbol{y}$ and the design matrix $\\boldsymbol{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "h3mlgrrnw7g",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X_std[X_std == 0] = 1\n",
    "X_norm = (X - X_mean) / X_std\n",
    "\n",
    "y_mean = y.mean()\n",
    "y_centered = y - y_mean\n",
    "\n",
    "def check_centering():\n",
    "    print(f\"y mean: {y.mean()}\")\n",
    "    print(f\"y_centered mean: {y_centered.mean()}\")\n",
    "\n",
    "\n",
    "    from matplotlib import pyplot as plt \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax1.hist(y, bins=20, alpha=0.7)\n",
    "    ax1.axvline(y.mean(), color='red', linestyle='--')\n",
    "    ax1.set_xlim(-5, 25)\n",
    "\n",
    "    ax2.hist(y_centered, bins=20, alpha=0.7)\n",
    "    ax2.axvline(y_centered.mean(), color='red', linestyle='--')\n",
    "    ax2.set_xlim(-5, 25)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b70ce2",
   "metadata": {},
   "source": [
    "## Exercise 2, calculate the gradients\n",
    "\n",
    "Find the gradients for OLS and Ridge regression using the mean-squared error as cost/loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6176c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ols(X, y, theta):\n",
    "    n = len(y)\n",
    "    return (1/n) * X.T @ (X @ theta - y)\n",
    "\n",
    "def gradient_ridge(X, y, theta, lam):\n",
    "    n = len(y)\n",
    "    return (1/n) * X.T @ (X @ theta - y) + 2 * lam * theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tz96l8l6f2",
   "metadata": {},
   "source": [
    "## Exercise 3, using the analytical formulae for OLS and Ridge regression to find the optimal parameters $\\boldsymbol{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hqyitbkaehb",
   "metadata": {},
   "source": [
    "### 3a)\n",
    "\n",
    "Finalize, in the above code, the OLS and Ridge regression determination of the optimal parameters $\\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dhecmef9lh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed-form Ridge coefficients: [ 0.         -1.16566494  6.09212444]\n",
      "closed-form OLS coefficients: [ 0.         -1.1657815   6.09273365]\n"
     ]
    }
   ],
   "source": [
    "lam = 0.01\n",
    "\n",
    "n_features = X_norm.shape[1]\n",
    "I = np.eye(n_features)\n",
    "theta_closed_formRidge = np.linalg.pinv(X_norm.T @ X_norm + lam * I) @ X_norm.T @ y_centered\n",
    "theta_closed_formOLS = np.linalg.pinv(X_norm.T @ X_norm) @ X_norm.T @ y_centered\n",
    "\n",
    "print(\"closed-form Ridge coefficients:\", theta_closed_formRidge)\n",
    "print(\"closed-form OLS coefficients:\", theta_closed_formOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbmgdxe0j8",
   "metadata": {},
   "source": [
    "### 3b)\n",
    "\n",
    "Explore the results as function of different values of the hyperparameter $\\lambda$. See for example exercise 4 from week 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "xqsdqmaq49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda=0.001: [ 0.         -1.16576985  6.09267272]\n",
      "Lambda=0.01: [ 0.         -1.16566494  6.09212444]\n",
      "Lambda=0.1: [ 0.         -1.16461689  6.086647  ]\n",
      "Lambda=1.0: [ 0.         -1.15423911  6.03240955]\n",
      "Lambda=10.0: [ 0.         -1.05980137  5.53884877]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "ridge_coeffs = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    theta_ridge = np.linalg.inv(X_norm.T @ X_norm + lam * I) @ X_norm.T @ y_centered\n",
    "    ridge_coeffs.append(theta_ridge)\n",
    "    print(f\"Lambda={lam}: {theta_ridge}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ridge_coeffs = np.array(ridge_coeffs)\n",
    "for i in range(n_features):\n",
    "    plt.plot(lambdas, ridge_coeffs[:, i], marker='o', label=f'theta_{i}')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Coefficient value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ti0tbaxgi0i",
   "metadata": {},
   "source": [
    "## Exercise 4, Implementing the simplest form for gradient descent\n",
    "\n",
    "Alternatively, we can fit the ridge regression model using gradient descent. This is useful to visualize the iterative convergence and is necessary if $n$ and $p$ are so large that the closed-form might be too slow or memory-intensive. We derive the gradients from the cost functions defined above. Use the gradients of the Ridge and OLS cost functions with respect to the parameters $\\boldsymbol{\\theta}$ and set up your own gradient descent code for OLS and Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mumdgsa4cn",
   "metadata": {},
   "source": [
    "### 4a)\n",
    "\n",
    "Write first a gradient descent code for OLS only using the above template. Discuss the results as function of the learning rate parameters and the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lfhbgi8ils",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent OLS coefficients: [ 0.         -1.1657815   6.09273365]\n",
      "Closed-form OLS coefficients: [ 0.         -1.1657815   6.09273365]\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "num_iters = 1000\n",
    "\n",
    "theta_ols = np.zeros(n_features)\n",
    "\n",
    "for t in range(num_iters):\n",
    "    grad_OLS = gradient_ols(X_norm, y_centered, theta_ols)\n",
    "    theta_ols = theta_ols - eta * grad_OLS\n",
    "\n",
    "print(\"Gradient Descent OLS coefficients:\", theta_ols)\n",
    "print(\"Closed-form OLS coefficients:\", theta_closed_formOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w4flilgn5b",
   "metadata": {},
   "source": [
    "### 4b)\n",
    "\n",
    "Write then a similar code for Ridge regression using the above template. Try to add a stopping parameter as function of the number iterations and the difference between the new and old $\\theta$ values. How would you define a stopping criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fwvjxsuwi3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 125 iterations\n",
      "Gradient Descent Ridge coefficients: [ 0.         -1.14292139  5.97325966]\n",
      "Closed-form Ridge coefficients: [ 0.         -1.16566494  6.09212444]\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "num_iters = 1000\n",
    "tol = 1e-6\n",
    "lam = 0.01\n",
    "\n",
    "theta_ridge = np.zeros(n_features)\n",
    "\n",
    "for t in range(num_iters):\n",
    "    theta_old = theta_ridge.copy()\n",
    "    grad_Ridge = gradient_ridge(X_norm, y_centered, theta_ridge, lam)\n",
    "    theta_ridge = theta_ridge - eta * grad_Ridge\n",
    "    \n",
    "    if np.linalg.norm(theta_ridge - theta_old) < tol:\n",
    "        print(f\"Converged after {t+1} iterations\")\n",
    "        break\n",
    "\n",
    "print(\"Gradient Descent Ridge coefficients:\", theta_ridge)\n",
    "print(\"Closed-form Ridge coefficients:\", theta_closed_formRidge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch8ymhayli",
   "metadata": {},
   "source": [
    "**Stopping Criterion:**\n",
    "\n",
    "I would define a stopping criterion based on the change in parameters between iterations. When the L2 norm of the difference between consecutive parameter vectors falls below a tolerance threshold (e.g., `np.linalg.norm(theta_new - theta_old) < tol`), the algorithm has converged. This indicates that the parameters are no longer changing significantly, so we've found the minimum.\n",
    "\n",
    "As we can see from the prints, the closed forms and gradient descent are extremely close. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5mzvoikznnc",
   "metadata": {},
   "source": [
    "## Exercise 5, Ridge regression and a new Synthetic Dataset\n",
    "\n",
    "We create a synthetic linear regression dataset with a sparse underlying relationship. This means we have many features but only a few of them actually contribute to the target. In our example, we'll use 10 features with only 3 non-zero weights in the true model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9owwttwfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 100\n",
    "n_features = 10\n",
    "\n",
    "theta_true = np.array([5.0, -3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "X_synth = np.random.randn(n_samples, n_features)\n",
    "noise = 0.5 * np.random.randn(n_samples)\n",
    "y_synth = X_synth @ theta_true + noise\n",
    "\n",
    "X_synth_norm = (X_synth - X_synth.mean(axis=0)) / X_synth.std(axis=0)\n",
    "y_synth_centered = y_synth - y_synth.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d366jz8icrs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True coefficients: [ 5. -3.  0.  0.  0.  0.  2.  0.  0.  0.]\n",
      "OLS Analytical: [ 5.03241281e+00 -2.89258175e+00 -1.55189951e-02  1.51795012e-01\n",
      " -6.83299260e-02 -4.40147965e-02  1.76999871e+00  4.37643569e-03\n",
      "  4.52550260e-02 -4.97610000e-02]\n",
      "OLS Gradient Descent: [ 5.03052627e+00 -2.88962545e+00 -1.54631907e-02  1.53537540e-01\n",
      " -7.12034281e-02 -4.55513413e-02  1.76973981e+00  4.18611669e-03\n",
      "  4.31429304e-02 -4.94513872e-02]\n",
      "Ridge Analytical: [ 5.02716096e+00 -2.88896347e+00 -1.55169486e-02  1.52287662e-01\n",
      " -6.93302234e-02 -4.47229113e-02  1.76836298e+00  4.62139092e-03\n",
      "  4.41380481e-02 -4.96664608e-02]\n",
      "Ridge Gradient Descent: [ 4.17145961 -2.3219415  -0.01540697  0.20874048 -0.1946188  -0.13721978\n",
      "  1.49447228  0.04064028 -0.10520121 -0.03682043]\n"
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "I_synth = np.eye(n_features)\n",
    "\n",
    "theta_ols_analytical = np.linalg.pinv(X_synth_norm) @ y_synth_centered\n",
    "theta_ridge_analytical = np.linalg.inv(X_synth_norm.T @ X_synth_norm + lam * I_synth) @ X_synth_norm.T @ y_synth_centered\n",
    "\n",
    "eta = 0.01\n",
    "num_iters = 1000\n",
    "\n",
    "theta_ols_gd = np.zeros(n_features)\n",
    "for t in range(num_iters):\n",
    "    grad = gradient_ols(X_synth_norm, y_synth_centered, theta_ols_gd)\n",
    "    theta_ols_gd = theta_ols_gd - eta * grad\n",
    "\n",
    "theta_ridge_gd = np.zeros(n_features)\n",
    "for t in range(num_iters):\n",
    "    grad = gradient_ridge(X_synth_norm, y_synth_centered, theta_ridge_gd, lam)\n",
    "    theta_ridge_gd = theta_ridge_gd - eta * grad\n",
    "\n",
    "print(\"True coefficients:\", theta_true)\n",
    "print(\"OLS Analytical:\", theta_ols_analytical)\n",
    "print(\"OLS Gradient Descent:\", theta_ols_gd)\n",
    "print(\"Ridge Analytical:\", theta_ridge_analytical)\n",
    "print(\"Ridge Gradient Descent:\", theta_ridge_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sx57aps11d",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "Ridge regression performs better than OLS for this sparse dataset. Ridge shrinks the coefficients toward zero, which helps when many features are irrelevant (have true coefficient = 0). The regularization penalty helps Ridge identify the important features (0, 1, and 6) while suppressing noise in the irrelevant features. OLS tends to overfit and assigns non-zero weights to irrelevant features due to noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
